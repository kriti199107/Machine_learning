{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kriti\\Documents\\Udacity\\Machine_learning\\ud120-projects\\final_project\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/kriti/Documents/Udacity/Machine_learning/ud120-projects/final_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load poi_id.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"C:/Users/kriti/Documents/Udacity/Machine_learning/ud120-projects/final_project/final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    enron_data = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enron_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POI=[]\n",
    "non_POI=[]\n",
    "\n",
    "for person in enron_data.keys():\n",
    "    features_list=enron_data[person]\n",
    "    for item in features_list.keys():\n",
    "        feature=item\n",
    "        if feature==\"poi\":\n",
    "            label=features_list[\"poi\"]\n",
    "            if label==0:\n",
    "                non_POI.append(label)\n",
    "            else:\n",
    "                POI.append(label)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(POI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_POI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1358\n"
     ]
    }
   ],
   "source": [
    "missing_values=[]\n",
    "for person in enron_data.keys():\n",
    "    features_list=enron_data[person]\n",
    "    for item in features_list.values():\n",
    "        if item==\"NaN\":\n",
    "            missing_values.append(item)\n",
    "print len(missing_values)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to_messages': 5, 'deferral_payments': 10, 'bonus_to_salary_ratio': 15, 'expenses': 20, 'poi': 25, 'deferred_income': 30, 'email_address': 35, 'from_poi_to_this_person': 85, 'restricted_stock_deferred': 45, 'shared_receipt_with_poi': 50, 'loan_advances': 55, 'from_messages': 60, 'other': 65, 'director_fees': 70, 'bonus': 75, 'total_stock_value': 80, 'from_this_person_to_poi': 90, 'long_term_incentive': 40, 'restricted_stock': 95, 'salary': 100, 'total_payments': 105, 'exercised_stock_options': 110}\n"
     ]
    }
   ],
   "source": [
    "missing_values_features={}\n",
    "\n",
    "for person in enron_data.keys():\n",
    "    count=[]\n",
    "    features_list=enron_data[person]\n",
    "    for item in features_list:\n",
    "        feature=item\n",
    "        \n",
    "        for data in features_list.values():\n",
    "            \n",
    "            if data==\"NaN\":\n",
    "                count.append(\"missing\")\n",
    "                length=len(count)\n",
    "                missing_values_features[feature]=length\n",
    "\n",
    "print missing_values_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "features_total=[]\n",
    "for person in enron_data.keys():\n",
    "    features_list=enron_data[person]\n",
    "    for item in features_list.keys():\n",
    "        feature=item\n",
    "        if feature not in features_total and feature!= \"email_address\" and feature!=\"poi\":\n",
    "            features_total.append(feature)\n",
    "\n",
    "print features_total            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "#making \"poi\" as the first item in the list\n",
    "features_total.insert(0, \"poi\")\n",
    "print features_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# formatting the data and splitting it into out target and main features\n",
    "import numpy as np\n",
    "data_modified=featureFormat( enron_data, features_total, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False  True  True  True False  True  True False  True\n",
      " False False False  True False False False]\n",
      "[ 7  1  6  2  1  1  1  9  1  1  8  1 10  4 12  1  5  3 11]\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination to select important features \n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 6 attributes\n",
    "rfe = RFE(model,8 )\n",
    "rfe = rfe.fit(features, target)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to_messages', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred', 'total_stock_value', 'loan_advances', 'director_fees']\n"
     ]
    }
   ],
   "source": [
    "support=np.array(rfe.ranking_)\n",
    "features_selected=[]\n",
    "for i in range(1, len(support)):\n",
    "    if support[i]==1:\n",
    "        features_selected.append(features_total[i+1])\n",
    "        \n",
    "print features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### there's an outlier--remove it! \n",
    "enron_data.pop(\"TOTAL\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new feature\n",
    "\n",
    "Since bonus is relative to the salary, we can create a new feature called \"bonus_to_salary\" which is the ratio of bonus to salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#general function to compute ratio of two initial features\n",
    "\n",
    "def compute_ratio(numerator, denominator):\n",
    "    if (numerator==\"NaN\") or (denominator==\"NaN\") or (denominator==0):\n",
    "        fraction=0\n",
    "    else:\n",
    "        fraction=float(numerator)/float(denominator)\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create new finacial feature\n",
    "def add_bonus_to_salary_ratio(dict):\n",
    "    for key in dict:\n",
    "        bonus=dict[key][\"bonus\"]\n",
    "        salary=dict[key][\"salary\"]\n",
    "        bonus_to_salary=compute_ratio(bonus, salary)\n",
    "        dict[key][\"bonus_to_salary_ratio\"]=bonus_to_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"C:/Users/kriti/Documents/Udacity/Machine_learning/ud120-projects/final_project/final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    enron_data = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to_messages', 'deferral_payments', 'bonus_to_salary_ratio', 'expenses', 'deferred_income', 'long_term_incentive', 'restricted_stock_deferred', 'shared_receipt_with_poi', 'loan_advances', 'from_messages', 'other', 'director_fees', 'total_stock_value', 'from_poi_to_this_person', 'from_this_person_to_poi', 'restricted_stock', 'total_payments', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "add_bonus_to_salary_ratio(enron_data)\n",
    "\n",
    "features_modified=[]\n",
    "for person in enron_data.keys():\n",
    "    features_list=enron_data[person]\n",
    "    for item in features_list.keys():\n",
    "        feature=item\n",
    "        if feature not in features_modified and feature!= \"email_address\" and feature!=\"poi\" and feature!=\"bonus\" and feature!=\"salary\":\n",
    "            features_modified.append(feature)\n",
    "\n",
    "print features_modified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_modified.insert(0, \"poi\")\n",
    "data_modified=featureFormat( enron_data, features_modified, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False False False  True False  True False  True\n",
      "  True False  True  True False  True]\n",
      "[ 1  4 10  2  6  7  3  1 11  1  8  1  1  5  1  1  9  1]\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination to select important features \n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 6 attributes\n",
    "rfe = RFE(model,8 )\n",
    "rfe = rfe.fit(features, target)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shared_receipt_with_poi', 'from_messages', 'director_fees', 'total_stock_value', 'from_this_person_to_poi', 'restricted_stock', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "support=np.array(rfe.ranking_)\n",
    "features_selected=[]\n",
    "for i in range(1, len(support)):\n",
    "    if support[i]==1:\n",
    "        features_selected.append(features_modified[i+1])\n",
    "        \n",
    "print features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shared_receipt_with_poi',\n",
       " 'from_messages',\n",
       " 'director_fees',\n",
       " 'total_stock_value',\n",
       " 'from_this_person_to_poi',\n",
       " 'restricted_stock',\n",
       " 'exercised_stock_options']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_final=[\"poi\", 'shared_receipt_with_poi', 'from_messages', 'director_fees', 'total_stock_value', 'from_this_person_to_poi', 'restricted_stock', 'exercised_stock_options' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_final, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.4, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.315789473684\n",
      "0.6\n",
      "0.075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train,target_train )\n",
    "GaussianNB(priors=None)\n",
    "pred=clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(pred,target_test )\n",
    "precision=precision_score(pred,target_test)\n",
    "recall=recall_score(pred,target_test)\n",
    "\n",
    "print accuracy\n",
    "print precision\n",
    "print recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912280701754\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kriti\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "features_train = min_max_scaler.fit_transform(features_train)\n",
    "features_test = min_max_scaler.fit_transform(features_test)\n",
    "\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(features_train,target_train )\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "pred=clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(pred,target_test )\n",
    "precision=precision_score(pred,target_test)\n",
    "recall=recall_score(pred,target_test)\n",
    "\n",
    "print accuracy\n",
    "print precision\n",
    "print recall \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912280701754\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## change the parameters and put C=3.0\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(features_train,target_train )\n",
    "SVC(C=3.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "pred=clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(pred,target_test )\n",
    "precision=precision_score(pred,target_test)\n",
    "recall=recall_score(pred,target_test)\n",
    "\n",
    "print accuracy\n",
    "print precision\n",
    "print recall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912280701754\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(features_train,target_train )\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "pred=clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(pred,target_test )\n",
    "precision=precision_score(pred,target_test)\n",
    "recall=recall_score(pred,target_test)\n",
    "\n",
    "print accuracy\n",
    "print precision\n",
    "print recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_final, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842105263158\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(features_train,target_train )\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "pred=clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(pred,target_test )\n",
    "precision=precision_score(pred,target_test)\n",
    "recall=recall_score(pred,target_test)\n",
    "\n",
    "print accuracy\n",
    "print precision\n",
    "print recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Out of the three SVC seems to be most accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.79600\tPrecision: 0.25688\tRecall: 0.28000\tF1: 0.26794\tF2: 0.27505\n",
      "\tTotal predictions: 1500\tTrue positives:   56\tFalse positives:  162\tFalse negatives:  144\tTrue negatives: 1138\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kriti\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification report\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('tree', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=25,\n",
      "            max_featu...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.80720\tPrecision: 0.23734\tRecall: 0.20150\tF1: 0.21796\tF2: 0.20777\n",
      "\tTotal predictions: 15000\tTrue positives:  403\tFalse positives: 1295\tFalse negatives: 1597\tTrue negatives: 11705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_final, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "# use scaling in GridSearchCV\n",
    "Min_Max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), ('pca',PCA(n_components = 2)), ('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, target)\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_total=['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person',\"bonus_to_salary_ratio\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_total, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.76933\tPrecision: 0.12755\tRecall: 0.12500\tF1: 0.12626\tF2: 0.12550\n",
      "\tTotal predictions: 1500\tTrue positives:   25\tFalse positives:  171\tFalse negatives:  175\tTrue negatives: 1129\n",
      "\n",
      "Tester Classification report\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('tree', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=15,\n",
      "            max_featu...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.78420\tPrecision: 0.16872\tRecall: 0.15750\tF1: 0.16292\tF2: 0.15962\n",
      "\tTotal predictions: 15000\tTrue positives:  315\tFalse positives: 1552\tFalse negatives: 1685\tTrue negatives: 11448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_total, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "# use scaling in GridSearchCV\n",
    "Min_Max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), ('pca',PCA(n_components = 2)), ('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, target)\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, enron_data, features_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_total, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.76933\tPrecision: 0.12755\tRecall: 0.12500\tF1: 0.12626\tF2: 0.12550\n",
      "\tTotal predictions: 1500\tTrue positives:   25\tFalse positives:  171\tFalse negatives:  175\tTrue negatives: 1129\n",
      "\n",
      "Tester Classification report\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('tree', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=25,\n",
      "            max_featu...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.78433\tPrecision: 0.17137\tRecall: 0.16100\tF1: 0.16602\tF2: 0.16297\n",
      "\tTotal predictions: 15000\tTrue positives:  322\tFalse positives: 1557\tFalse negatives: 1678\tTrue negatives: 11443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "features_new = SelectKBest(k=3).fit_transform(features, target)\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_total, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "# use scaling in GridSearchCV\n",
    "Min_Max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), ('pca',PCA(n_components = 2)), ('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features_new, target)\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0035723084503572313, 0.017763092806303869, 0.025869535666375898, 0.034187102631984524, 0.03539624460723545, 0.042564821565998057, 0.042693254697697088, 0.043200421921383833, 0.045885817369826699, 0.054366238608233572, 0.056483892824947222, 0.059574286758886, 0.060874911361298946, 0.091097404460271952, 0.11421545585670964, 0.12725583467831755, 0.14499937573417249]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "names = features_total\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(features, target)\n",
    "\n",
    "scores=rf.feature_importances_\n",
    "mean=np.mean(scores)\n",
    "print sorted(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to_messages', 'total_payments', 'exercised_stock_options', 'restricted_stock', 'shared_receipt_with_poi', 'expenses', 'from_messages', 'other']\n"
     ]
    }
   ],
   "source": [
    "features_selected_RF=[]\n",
    "for i in range(1, len(scores)):\n",
    "    if scores[i]>=mean:\n",
    "        features_selected_RF.append(features_total[i+1])\n",
    "        \n",
    "print features_selected_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_selected_RF=[\"poi\", 'to_messages', 'total_payments', 'exercised_stock_options', 'restricted_stock', 'shared_receipt_with_poi', 'expenses', 'from_messages', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_selected_RF, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.79533\tPrecision: 0.20765\tRecall: 0.19000\tF1: 0.19843\tF2: 0.19329\n",
      "\tTotal predictions: 1500\tTrue positives:   38\tFalse positives:  145\tFalse negatives:  162\tTrue negatives: 1155\n",
      "\n",
      "Tester Classification report\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
      "            max_features...    min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'))])\n",
      "\tAccuracy: 0.81887\tPrecision: 0.27774\tRecall: 0.22400\tF1: 0.24799\tF2: 0.23302\n",
      "\tTotal predictions: 15000\tTrue positives:  448\tFalse positives: 1165\tFalse negatives: 1552\tTrue negatives: 11835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_selected_RF, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "# use scaling in GridSearchCV\n",
    "Min_Max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), ('pca',PCA(n_components = 2)), ('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, target)\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_selected_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.79533\tPrecision: 0.20765\tRecall: 0.19000\tF1: 0.19843\tF2: 0.19329\n",
      "\tTotal predictions: 1500\tTrue positives:   38\tFalse positives:  145\tFalse negatives:  162\tTrue negatives: 1155\n",
      "\n",
      "Tester Classification report\n",
      "Pipeline(steps=[('tree', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=30, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "\tAccuracy: 0.80467\tPrecision: 0.25629\tRecall: 0.24450\tF1: 0.25026\tF2: 0.24677\n",
      "\tTotal predictions: 15000\tTrue positives:  489\tFalse positives: 1419\tFalse negatives: 1511\tTrue negatives: 11581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_selected_RF, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, target)\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_selected_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_final=[\"poi\", 'shared_receipt_with_poi', 'from_messages', 'director_fees', 'total_stock_value', 'from_this_person_to_poi', 'restricted_stock', 'exercised_stock_options' ]\n",
    "\n",
    "data_modified=featureFormat( enron_data, features_final, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.79067\tPrecision: 0.21500\tRecall: 0.21500\tF1: 0.21500\tF2: 0.21500\n",
      "\tTotal predictions: 1500\tTrue positives:   43\tFalse positives:  157\tFalse negatives:  157\tTrue negatives: 1143\n",
      "\n",
      "Tester Classification report\n",
      "Pipeline(steps=[('tree', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=15,\n",
      "            max_features=None, max_leaf_nodes=30, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'))])\n",
      "\tAccuracy: 0.80793\tPrecision: 0.25294\tRecall: 0.22550\tF1: 0.23844\tF2: 0.23050\n",
      "\tTotal predictions: 15000\tTrue positives:  451\tFalse positives: 1332\tFalse negatives: 1549\tTrue negatives: 11668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## features selected by RCE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_final, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, target)\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different methods to improve accuracy and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_total=['poi',\n",
    " 'salary',\n",
    " 'to_messages',\n",
    " 'deferral_payments',\n",
    " 'total_payments',\n",
    " 'exercised_stock_options',\n",
    " 'bonus',\n",
    " 'restricted_stock',\n",
    " 'shared_receipt_with_poi',\n",
    " 'restricted_stock_deferred',\n",
    " 'total_stock_value',\n",
    " 'expenses',\n",
    " 'loan_advances',\n",
    " 'from_messages',\n",
    " 'other',\n",
    " 'from_this_person_to_poi',\n",
    " 'director_fees',\n",
    " 'deferred_income',\n",
    " 'long_term_incentive',\n",
    " 'from_poi_to_this_person'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to_messages', 'deferral_payments', 'bonus_to_salary_ratio', 'expenses', 'deferred_income', 'long_term_incentive', 'restricted_stock_deferred', 'shared_receipt_with_poi', 'loan_advances', 'from_messages', 'other', 'director_fees', 'total_stock_value', 'from_poi_to_this_person', 'from_this_person_to_poi', 'restricted_stock', 'total_payments', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "add_bonus_to_salary_ratio(enron_data)\n",
    "\n",
    "features_modified=[]\n",
    "for person in enron_data.keys():\n",
    "    features_list=enron_data[person]\n",
    "    for item in features_list.keys():\n",
    "        feature=item\n",
    "        if feature not in features_modified and feature!= \"email_address\" and feature!=\"poi\" and feature!=\"bonus\" and feature!=\"salary\":\n",
    "            features_modified.append(feature)\n",
    "\n",
    "print features_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.pop(\"TOTAL\", 0)\n",
    "enron_data.pop(\"THE TRAVEL AGENCY IN THE PARK\", 0)\n",
    "enron_data.pop(\"LOCKHART EUGENE E\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_total, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deferral_payments', 'deferred_income', 'long_term_incentive', 'restricted_stock_deferred', 'from_messages', 'director_fees', 'total_stock_value', 'restricted_stock']\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination to select important features \n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 6 attributes\n",
    "rfe = RFE(model,8 )\n",
    "rfe = rfe.fit(features, target)\n",
    "\n",
    "support=np.array(rfe.ranking_)\n",
    "features_selected=[]\n",
    "for i in range(1, len(support)):\n",
    "    if support[i]==1:\n",
    "        features_selected.append(features_modified[i+1])\n",
    "        \n",
    "print features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'to_messages',\n",
       " 'total_payments',\n",
       " 'exercised_stock_options',\n",
       " 'restricted_stock',\n",
       " 'shared_receipt_with_poi',\n",
       " 'expenses',\n",
       " 'from_messages',\n",
       " 'other']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_selected_RF ## Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "names = features_total\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(features, target)\n",
    "\n",
    "scores=rf.feature_importances_\n",
    "mean=np.mean(scores)\n",
    "print sorted(rf.feature_importances_)\n",
    "\n",
    "features_selected_RF=[]\n",
    "for i in range(1, len(scores)):\n",
    "    if scores[i]>=mean:\n",
    "        features_selected_RF.append(features_total[i+1])\n",
    "        \n",
    "print features_selected_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_modified=['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person',\"bonus_to_salary_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'salary',\n",
       " 'to_messages',\n",
       " 'deferral_payments',\n",
       " 'total_payments',\n",
       " 'exercised_stock_options',\n",
       " 'bonus',\n",
       " 'restricted_stock',\n",
       " 'shared_receipt_with_poi',\n",
       " 'restricted_stock_deferred',\n",
       " 'total_stock_value',\n",
       " 'expenses',\n",
       " 'loan_advances',\n",
       " 'from_messages',\n",
       " 'other',\n",
       " 'from_this_person_to_poi',\n",
       " 'director_fees',\n",
       " 'deferred_income',\n",
       " 'long_term_incentive',\n",
       " 'from_poi_to_this_person']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_modified, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking: \n",
      "feature no. 1: exercised_stock_options (0.199840127898)\n",
      "feature no. 2: restricted_stock (0.120544942603)\n",
      "feature no. 3: expenses (0.117859952913)\n",
      "feature no. 4: total_payments (0.112987654321)\n",
      "feature no. 5: bonus (0.109131813741)\n",
      "feature no. 6: long_term_incentive (0.108952380952)\n",
      "feature no. 7: shared_receipt_with_poi (0.0577777777778)\n",
      "feature no. 8: from_poi_to_this_person (0.0556111111111)\n",
      "feature no. 9: from_this_person_to_poi (0.0554930118798)\n",
      "feature no. 10: salary (0.0317777777778)\n",
      "feature no. 11: other (0.0300234490255)\n",
      "feature no. 12: to_messages (0.0)\n",
      "feature no. 13: deferral_payments (0.0)\n",
      "feature no. 14: bonus_to_salary_ratio (0.0)\n",
      "feature no. 15: restricted_stock_deferred (0.0)\n",
      "feature no. 16: loan_advances (0.0)\n",
      "feature no. 17: from_messages (0.0)\n",
      "feature no. 18: director_fees (0.0)\n",
      "feature no. 19: deferred_income (0.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(features, target)\n",
    "importances = clf.feature_importances_\n",
    "importances = clf.feature_importances_\n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print 'Feature Ranking: '\n",
    "for i in range(19):\n",
    "    print \"feature no. {}: {} ({})\".format(i+1,features_modified[indices[i]+1],importances[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_selected_importances=[\"poi\", \"expenses\",\"bonus\",\"total_payments\", \"restricted_stock\", \"from_messages\", \"exercised_stock_options\"  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enron_data.pop(\"TOTAL\", 0)\n",
    "enron_data.pop(\"THE TRAVEL AGENCY IN THE PARK\", 0)\n",
    "enron_data.pop(\"LOCKHART EUGENE E\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_modified=featureFormat( enron_data, features_selected_importances, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.82667\tPrecision: 0.32759\tRecall: 0.28500\tF1: 0.30481\tF2: 0.29261\n",
      "\tTotal predictions: 1500\tTrue positives:   57\tFalse positives:  117\tFalse negatives:  143\tTrue negatives: 1183\n",
      "\n",
      "Tester Classification report\n",
      "Pipeline(steps=[('tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=15,\n",
      "            max_features=None, max_leaf_nodes=30, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'))])\n",
      "\tAccuracy: 0.81720\tPrecision: 0.33303\tRecall: 0.37000\tF1: 0.35054\tF2: 0.36196\n",
      "\tTotal predictions: 15000\tTrue positives:  740\tFalse positives: 1482\tFalse negatives: 1260\tTrue negatives: 11518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_selected_importances, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "\n",
    "gs.fit(features, target)\n",
    "clf = gs.best_estimator_\n",
    "#importances = clf.feature_importances_\n",
    "\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_selected_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final order that worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking: \n",
      "feature no. 1: exercised_stock_options (0.199840127898)\n",
      "feature no. 2: restricted_stock (0.152322720381)\n",
      "feature no. 3: other (0.138975829978)\n",
      "feature no. 4: expenses (0.117859952913)\n",
      "feature no. 5: total_payments (0.112987654321)\n",
      "feature no. 6: bonus (0.109131813741)\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=1, splitter='best')\n",
      "\tAccuracy: 0.82200\tPrecision: 0.32642\tRecall: 0.31500\tF1: 0.32061\tF2: 0.31722\n",
      "\tTotal predictions: 1500\tTrue positives:   63\tFalse positives:  130\tFalse negatives:  137\tTrue negatives: 1170\n",
      "\n",
      "Tester Classification report\n",
      "Pipeline(steps=[('tree', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=30,\n",
      "            max_features=None, max_leaf_nodes=30, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'))])\n",
      "\tAccuracy: 0.81353\tPrecision: 0.30942\tRecall: 0.32350\tF1: 0.31630\tF2: 0.32058\n",
      "\tTotal predictions: 15000\tTrue positives:  647\tFalse positives: 1444\tFalse negatives: 1353\tTrue negatives: 11556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_total=['poi',\n",
    " 'salary',\n",
    " 'to_messages',\n",
    " 'deferral_payments',\n",
    " 'total_payments',\n",
    " 'exercised_stock_options',\n",
    " 'bonus',\n",
    " 'restricted_stock',\n",
    " 'shared_receipt_with_poi',\n",
    " 'restricted_stock_deferred',\n",
    " 'total_stock_value',\n",
    " 'expenses',\n",
    " 'loan_advances',\n",
    " 'from_messages',\n",
    " 'other',\n",
    " 'from_this_person_to_poi',\n",
    " 'director_fees',\n",
    " 'deferred_income',\n",
    " 'long_term_incentive',\n",
    " 'from_poi_to_this_person'\n",
    "]\n",
    "\n",
    "enron_data.pop(\"TOTAL\", 0)\n",
    "enron_data.pop(\"THE TRAVEL AGENCY IN THE PARK\", 0)\n",
    "enron_data.pop(\"LOCKHART EUGENE E\", 0)\n",
    "\n",
    "data_modified=featureFormat( enron_data, features_total, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(features, target)\n",
    "importances = clf.feature_importances_\n",
    "importances = clf.feature_importances_\n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print 'Feature Ranking: '\n",
    "for i in range(6):\n",
    "    print \"feature no. {}: {} ({})\".format(i+1,features_total[indices[i]+1],importances[indices[i]])\n",
    "\n",
    "    \n",
    "    features_selected_importances=[\"poi\", \"expenses\",\"bonus\",\"total_payments\", \"restricted_stock\", \"long_term_incentive\", \"exercised_stock_options\" ]\n",
    "#\"poi\", \"expenses\",\"bonus\",\"total_payments\", \"restricted_stock\", long_term_incentive, \"exercised_stock_options\"]\n",
    "###\"poi\", \"expenses\",\"bonus\",\"total_payments\", \"restricted_stock\", \"from_messages\", \"exercised_stock_options\"     \n",
    "data_modified=featureFormat( enron_data, features_selected_importances, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False)\n",
    "target, features=targetFeatureSplit( data_modified )\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tester import test_classifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "test_classifier(DecisionTreeClassifier( random_state = 1), enron_data, features_selected_importances, folds = 100)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25,30],\n",
    "                'tree__max_leaf_nodes':[5,10,30]}\n",
    "\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(target, 100, random_state = 42)\n",
    "\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, target)\n",
    "clf = gs.best_estimator_\n",
    "#importances = clf.feature_importances_\n",
    "\n",
    "\n",
    "# import test_classifier from tester.py\n",
    "from tester import test_classifier\n",
    "print \"Tester Classification report\" \n",
    "test_classifier(clf, enron_data, features_selected_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, enron_data, features_selected_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
